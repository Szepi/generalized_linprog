%!TEX root =  autocontgrlp.tex
\begin{abstract}
Approximate linear programming (ALP) and its variants have been widely applied to Markov Decision Processes (MDPs) with a large number of states. A serious limitation of ALP is that it has an intractable number of constraints, as a result of which constraint approximations are of interest. In this paper, we define a linearly relaxed approximation linear program (LRALP) that has a tractable number of constraints, obtained as positive linear combinations of the original constraints of the ALP. The main contribution is a novel performance bound for LRALP.
%By providing a detailed error analysis for the GRLP, we justify usage of a linear architecture for approximating the dual variables. Unlike prior results on constraint sampling, our analysis is deterministic and is based on a novel contraction operator.
\end{abstract}
\begin{keywords}{
%Approximate Dynamic Programming (ADP), 
Markov Decision Processes (MDPs), Approximate Linear Programming (ALP), %Generalized Reduced Linear Program (GRLP), 
%Constraint Sampling, Reinforcement Learning
}
\end{keywords}
